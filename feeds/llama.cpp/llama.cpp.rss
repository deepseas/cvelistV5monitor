<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>CVE Feed for llama.cpp -- llama.cpp</title>
    <link>https://raw.githubusercontent.com/deepseas/cvelistV5monitor/main/feeds/llama.cpp/llama.cpp.rss</link>
    <description>The latest CVEs for llama.cpp -- llama.cpp</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 27 Aug 2024 20:23:47 +0000</lastBuildDate>
    <ttl>60</ttl>
    <item>
      <title>CVE-2024-23496|2024-08-27T15:07:16.510Z -- llama.cpp -- llama.cpp
</title>
      <link>https://www.cve.org/CVERecord?id=CVE-2024-23496</link>
      <description>A heap-based buffer overflow vulnerability exists in the GGUF library gguf_fread_str functionality of llama.cpp Commit 18c2e17. A specially crafted .gguf file can lead to code execution. An attacker can provide a malicious file to trigger this vulnerability.</description>
      <guid isPermaLink="false">CVE-2024-23496|2024-08-27T15:07:16.510Z</guid>
      <pubDate>Mon, 26 Feb 2024 16:07:52 +0000</pubDate>
    </item>
  </channel>
</rss>
