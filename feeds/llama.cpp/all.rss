<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>CVE Feed for llama.cpp -- all</title>
    <link>https://raw.githubusercontent.com/deepseas/cvelistV5monitor/main/feeds/llama.cpp/all.rss</link>
    <description>The latest CVEs for llama.cpp -- all products</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Wed, 28 Aug 2024 23:22:29 +0000</lastBuildDate>
    <ttl>60</ttl>
    <item>
      <title>CVE-2024-21802|2024-08-28T14:47:38.743Z -- llama.cpp -- llama.cpp
</title>
      <link>https://www.cve.org/CVERecord?id=CVE-2024-21802</link>
      <description>A heap-based buffer overflow vulnerability exists in the GGUF library info-&amp;gt;ne functionality of llama.cpp Commit 18c2e17. A specially crafted .gguf file can lead to code execution. An attacker can provide a malicious file to trigger this vulnerability.</description>
      <guid isPermaLink="false">CVE-2024-21802|2024-08-28T14:47:38.743Z</guid>
      <pubDate>Mon, 26 Feb 2024 16:07:51 +0000</pubDate>
    </item>
  </channel>
</rss>
