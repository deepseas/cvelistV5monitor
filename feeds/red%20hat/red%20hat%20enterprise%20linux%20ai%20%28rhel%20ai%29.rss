<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>CVE Feed for Red Hat -- Red Hat Enterprise Linux AI (RHEL AI)</title>
    <link>https://raw.githubusercontent.com/deepseas/cvelistV5monitor/main/feeds/red%20hat/red%20hat%20enterprise%20linux%20ai%20%28rhel%20ai%29.rss</link>
    <description>The latest CVEs for Red Hat -- Red Hat Enterprise Linux AI (RHEL AI)</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <lastBuildDate>Tue, 17 Sep 2024 20:23:52 +0000</lastBuildDate>
    <ttl>60</ttl>
    <item>
      <title>CVE-2024-8939|2024-09-17T19:51:22.039Z -- red%20hat -- red%20hat%20enterprise%20linux%20ai%20%28rhel%20ai%29
</title>
      <link>https://www.cve.org/CVERecord?id=CVE-2024-8939</link>
      <description>A vulnerability was found in the ilab model serve component, where improper handling of the best_of parameter in the vllm JSON web API can lead to a Denial of Service (DoS). The API used for LLM-based sentence or chat completion accepts a best_of parameter to return the best completion from several options. When this parameter is set to a large value, the API does not handle timeouts or resource exhaustion properly, allowing an attacker to cause a DoS by consuming excessive system resources. This leads to the API becoming unresponsive, preventing legitimate users from accessing the service.</description>
      <guid isPermaLink="false">CVE-2024-8939|2024-09-17T19:51:22.039Z</guid>
      <pubDate>Tue, 17 Sep 2024 16:21:15 +0000</pubDate>
    </item>
    <item>
      <title>CVE-2024-8939|2024-09-17T16:21:15.222Z -- red%20hat -- red%20hat%20enterprise%20linux%20ai%20%28rhel%20ai%29</title>
      <link>https://www.cve.org/CVERecord?id=CVE-2024-8939</link>
      <description>A vulnerability was found in the ilab model serve component, where improper handling of the best_of parameter in the vllm JSON web API can lead to a Denial of Service (DoS). The API used for LLM-based sentence or chat completion accepts a best_of parameter to return the best completion from several options. When this parameter is set to a large value, the API does not handle timeouts or resource exhaustion properly, allowing an attacker to cause a DoS by consuming excessive system resources. This leads to the API becoming unresponsive, preventing legitimate users from accessing the service.</description>
      <guid isPermaLink="false">CVE-2024-8939|2024-09-17T16:21:15.222Z</guid>
      <pubDate>Tue, 17 Sep 2024 16:21:15 +0000</pubDate>
    </item>
    <item>
      <title>CVE-2024-8768|2024-09-17T16:20:42.399Z -- red%20hat -- red%20hat%20enterprise%20linux%20ai%20%28rhel%20ai%29</title>
      <link>https://www.cve.org/CVERecord?id=CVE-2024-8768</link>
      <description>A flaw was found in the vLLM library. A completions API request with an empty prompt will crash the vLLM API server, resulting in a denial of service.</description>
      <guid isPermaLink="false">CVE-2024-8768|2024-09-17T16:20:42.399Z</guid>
      <pubDate>Tue, 17 Sep 2024 16:20:42 +0000</pubDate>
    </item>
    <item>
      <title>CVE-2024-8768|2024-09-17T18:21:54.878Z -- red%20hat -- red%20hat%20enterprise%20linux%20ai%20%28rhel%20ai%29</title>
      <link>https://www.cve.org/CVERecord?id=CVE-2024-8768</link>
      <description>A flaw was found in the vLLM library. A completions API request with an empty prompt will crash the vLLM API server, resulting in a denial of service.</description>
      <guid isPermaLink="false">CVE-2024-8768|2024-09-17T18:21:54.878Z</guid>
      <pubDate>Tue, 17 Sep 2024 16:20:42 +0000</pubDate>
    </item>
  </channel>
</rss>
